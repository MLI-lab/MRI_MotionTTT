{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we demonstrate how to apply our proposed MotionTTT to estimate a simulated motion trajectory on an example from the [Calgary Campinas Brain MRI Dataset (CC359)](https://portal.conp.ca/dataset?id=projects/calgary-campinas#) using the pre-trained U-net from https://huggingface.co/mli-lab/Unet48-2D-CC359.\n",
    "\n",
    "The U-net was trained on the training set from CC359 on the task of 2D reconstruction from motion-free undersampled measurements as described in [MotionTTT: 2D Test-Time-Training Motion Estimation for 3D Motion Corrected MRI](https://arxiv.org/abs/2409.09370).\n",
    "\n",
    "\n",
    "#### 1. Setup data loading\n",
    "\n",
    "Please use the notebook `prepare_CC359_dataset.ipynb` to convert the hybrid k-space from CC359 and compute the sensitivity maps. We assume the converted validation data and sensitivity maps to be located in folders `Val_converted` and `Val_s_maps_3D` respectively. Start by selecting an example from our test set and set the file paths accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./codebase/')\n",
    "\n",
    "from codebase.functions.utils.helpers.helpers_getargs import get_args\n",
    "\n",
    "args = get_args()\n",
    "\n",
    "# # Select first example from the testset\n",
    "with open(\"codebase/data_files/volume_dataset_freqEnc170_test_len10.pickle\",'rb') as fn: example_dict = pickle.load(fn)[0]\n",
    "filename = example_dict[\"filename\"]\n",
    "\n",
    "# # Set file paths\n",
    "path_to_data = \"/media/ssd1/cc-359_raw/calgary-campinas_version-1.0/CC359/Raw-data/Multi-channel/12-channel\" # ! adjust\n",
    "path_to_result_dir = \".\"\n",
    "results_dir = \"experiments_results\"\n",
    "args.experiment_run_folder_name = \"motionTTT_interShot_Unet48-2D-CC359\"\n",
    "\n",
    "args.example_path = f\"{path_to_data}/Val_converted/{filename}\"\n",
    "args.mask_path= \"codebase/data_files/mask_3D_size_218_170_256_R_4_poisson_disc.pickle\"\n",
    "args.sensmaps_path = f\"{path_to_data}/Val_s_maps_3D/smaps_{filename}\"\n",
    "\n",
    "# # Load a model from huggingface:\n",
    "args.model= 'unet'\n",
    "args.chans= 48\n",
    "args.load_model_from_huggingface = \"mli-lab/Unet48-2D-CC359\"\n",
    "\n",
    "\n",
    "print(f\"Apply motionTTT to example {filename} from the CC359 validation set using the pre-trained model from {args.load_model_from_huggingface}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setup parameters for simulated motion and sampling trajectory\n",
    "\n",
    "In this example we consider inter-shot motion with 5 motion events and a maximum possible rotations/translations in [-5,+5]. We generate a motion trajectory that is unique to this test example by using the seed stored in `example_dict`.\n",
    "\n",
    "We assume the k-space was acquired within 50 shots and with an interleaved Cartesian sampling trajectory, where the center k-space was acquired in the first shot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define motion trajectory\n",
    "args.motionTraj_simMot = \"uniform_interShot_event_model\" \n",
    "args.Ns = 50 # Number of initial motion states (must be equal to the number of shots)\n",
    "args.num_shots = 50\n",
    "args.num_motion_events = 5\n",
    "args.max_trans = 5\n",
    "args.max_rot = 5\n",
    "args.random_motion_seed = example_dict[\"motion_seeds\"][\"seed1\"]\n",
    "\n",
    "# # Define sampling trajectory\n",
    "args.sampTraj_simMot = \"interleaved_cartesian\"\n",
    "args.center_in_first_state = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Setup the optimization scheme of MotionTTT\n",
    "\n",
    "**Phase 1**: Obtain an initial estimate of one set of motion parameters (3 rotations, 3 translations) per shot. Start with a large learning rate and decay twice. Run for 70 steps.\n",
    "\n",
    "**Phase 2**: Reset motion parameters of shots with a data consistency loss larger than a certain threshold to the average between the previous and next motion state that fall below the threshold. Then optimize only over the reset motion parameters for 30 steps. If no motion parameters to reset continue with phase 1 until `num_steps_TTT` is reached.\n",
    "\n",
    "**Phase 3**: If motion parameters have been reset in phase 2, phase 3 again optimizes over all motion parameters for another 30 steps with a small learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.TTT = True\n",
    "\n",
    "# Optimizer\n",
    "args.TTT_optimizer = 'Adam'\n",
    "# Total number of steps\n",
    "args.num_steps_TTT= 130 \n",
    "# Randomly sample the axis for 2D reconstruction in each step\n",
    "args.TTT_all_axes= True \n",
    "# Clamp motion parameters during first steps\n",
    "args.TTT_use_clamp_schedule = True\n",
    "# Number randomly slected of slices for which gradients are backpropagated in each step\n",
    "args.num_slices_per_grad_step= 5\n",
    "# Do not estimate motion parameters for the first shot (reference orientation)\n",
    "args.fix_mot_maxksp_shot = True \n",
    "# Use density compensation adjoint nufft with density compensation\n",
    "args.TTT_use_nufft_with_dcomp = True \n",
    "\n",
    "# # Phase 1 parameters\n",
    "args.lr_TTT= 4.0 \n",
    "args.TTT_lr_max_decays = 3\n",
    "args.TTT_lr_decay_factor = 0.25\n",
    "args.TTT_lr_decay_at_the_latest = [39,59,1000]\n",
    "args.TTT_num_rot_only_grad_steps = 5\n",
    "\n",
    "# # Phase 2 parameters\n",
    "args.TTT_list_of_split_steps = [71]\n",
    "args.TTT_states_per_split = 1\n",
    "args.TTT_lr_after_split = 0.5\n",
    "args.TTT_DCloss_th_split = 0.575\n",
    "\n",
    "# # Phase 3 parameters\n",
    "args.TTT_optimize_all_states_after = 100\n",
    "args.TTT_optimize_all_states_after_lr = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Setup GPU usage\n",
    "\n",
    "Specify gpu device index and the two parameters that control the gpu memory consumption `TTT_motState_batchSize_per_backprop` and `TTT_nufft_max_coil_size`:\n",
    "- `TTT_nufft_max_coil_size`: The (adjoint) NUFFT operates coil-wise. Hence, coils can be processed separately or in batches. Set to `None` to process all coils in one batch.\n",
    "- `TTT_motState_batchSize_per_backprop`: To further reduce gpu memory consumption we can compute the gradients of the motion parameters batch-wise. Once gradients are computed for all motion parameter, the parameters are updated. Set to `None` to compute all gradients in a single forward and backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.gpu= 0\n",
    "args.TTT_motState_batchSize_per_backprop = 50 # out of 50 initla motion states\n",
    "args.TTT_nufft_max_coil_size = 12 # out of total 12 coils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Run MotionTTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codebase.functions.utils.helpers.helpers_init import initialize_directories, init_TTT\n",
    "from codebase.functions.utils.models.helpers_model import get_model\n",
    "from codebase.functions.motionTTT_src.unet_TTT_simData_module import UnetTTTModuleSim\n",
    "\n",
    "# # Set experiment name\n",
    "args.experiment_name_TTT= f\"_rottrans{args.max_rot}_Ns{args.Ns}_motEvents{args.num_motion_events}_motSeed{args.random_motion_seed}\"\n",
    "\n",
    "# # Create directories, initialize logging\n",
    "args = initialize_directories(args, results_path = os.path.join(path_to_result_dir, results_dir))\n",
    "init_TTT(args)\n",
    "\n",
    "# # Get model from huggingface\n",
    "model, _, _, _ = get_model(args)\n",
    "\n",
    "# # Initialize MotionTTT module for simulated motion on the CC359 dataset\n",
    "TTT_module = UnetTTTModuleSim(args, model)\n",
    "\n",
    "# # Run motionTTT\n",
    "TTT_module.run_TTT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Run L1-minimization based on motion parameters estimated by MotionTTT\n",
    "\n",
    "Next, we obtain the final reconstruction using classical L1-minimization with a wavelet regularizer. Here, any other reconstruction mehod for motion-free data could be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codebase.functions.utils.helpers.helpers_init import init_L1min\n",
    "from codebase.functions.baselines_src.L1min_simData_module import L1minModuleSim\n",
    "\n",
    "# # Setup parameters for L1-minimization\n",
    "args.L1min=True\n",
    "args.L1min_mode = 'pred_mot_motionTTT'\n",
    "\n",
    "args.L1min_optimizer = 'SGD'\n",
    "args.L1min_lr = 5e7\n",
    "args.L1min_lambda = 1e-3\n",
    "args.L1min_num_steps = 50\n",
    "args.L1min_DC_threshold = 0.575\n",
    "\n",
    "# Control gpu memory consumption\n",
    "args.L1min_nufft_max_coil_size = 12 \n",
    "\n",
    "if os.path.exists(os.path.join(args.TTT_results_path_numerical, \"phase2\")):\n",
    "    args.L1min_on_TTT_load_from_phase = 2\n",
    "else:\n",
    "    args.L1min_on_TTT_load_from_phase = 0       \n",
    "\n",
    "args.Ns = 50\n",
    "args.L1min_DC_loss_thresholding = True\n",
    "args.L1min_motion_alignment = True\n",
    "args.experiment_name_L1min= f\"phase{args.L1min_on_TTT_load_from_phase}_dcTh{args.L1min_DC_threshold}_{args.L1min_DC_loss_thresholding}_align_{args.L1min_motion_alignment}\"\n",
    "\n",
    "# # Create directories, initialize logging\n",
    "args = initialize_directories(args, results_path = os.path.join(path_to_result_dir, results_dir))\n",
    "init_L1min(args)\n",
    "\n",
    "# # Initialize L1-minimization module to perform reconstruction based on the motion parameters estimated by MotionTTT\n",
    "L1min_module = L1minModuleSim(args)\n",
    "\n",
    "# # Run L1-minimization\n",
    "L1min_module.run_L1min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Inspect results\n",
    "\n",
    "Display estimated motion parameters vs. ground truth motion parameters as well as data consistency loss before and after MotionTTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "phase = args.L1min_on_TTT_load_from_phase\n",
    "\n",
    "step0_mot_params = Image.open(os.path.join(args.TTT_results_path, \"motion_param_figures_phase0\", \"motion_pred_params_0_axind_2.png\"))\n",
    "display(step0_mot_params)\n",
    "\n",
    "with open(os.path.join(args.TTT_results_path_numerical,f\"phase{phase}\",\"final_result_dict.pkl\"),'rb') as fn: best_step = pickle.load(fn)[\"TTT_best_step\"]\n",
    "\n",
    "stepbest_mot_params = Image.open(os.path.join(args.TTT_results_path, f\"motion_param_figures_phase{phase}\", f\"motion_pred_params_best_step_{best_step}_phase{phase}.png\"))\n",
    "display(stepbest_mot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display zero-filled motion corrupted images vs. final reconstructions based on L1-minimization with motion parameters estimated by MotionTTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "zf_corrupted_mid_slice_axial = Image.open(os.path.join(args.TTT_results_path, \"slice_images\", \"masked_corrupted_img_axial_128.png\"))\n",
    "zf_corrupted_mid_slice_coronal = Image.open(os.path.join(args.TTT_results_path, \"slice_images\", \"masked_corrupted_img_coronal_109.png\"))\n",
    "zf_corrupted_mid_slice_sagittal = Image.open(os.path.join(args.TTT_results_path, \"slice_images\", \"masked_corrupted_img_sagittal_85.png\"))\n",
    "\n",
    "MotionTTT_L1_mid_slice_axial = Image.open(os.path.join(args.L1min_results_path, \"slice_images\", \"recon_min_reconDC_loss_img_axial_128.png\"))\n",
    "MotionTTT_L1_mid_slice_coronal = Image.open(os.path.join(args.L1min_results_path, \"slice_images\", \"recon_min_reconDC_loss_img_coronal_109.png\"))\n",
    "MotionTTT_L1_mid_slice_sagittal = Image.open(os.path.join(args.L1min_results_path, \"slice_images\", \"recon_min_reconDC_loss_img_sagittal_85.png\"))\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axs[0,0].imshow(zf_corrupted_mid_slice_axial)\n",
    "axs[0,0].set_title(\"Corrupted axial slice\")\n",
    "axs[0,0].axis('off')\n",
    "axs[0,1].imshow(zf_corrupted_mid_slice_coronal.rotate(-90, expand=True))\n",
    "axs[0,1].set_title(\"Corrupted coronal slice\")\n",
    "axs[0,1].axis('off')\n",
    "axs[0,2].imshow(zf_corrupted_mid_slice_sagittal.rotate(-90, expand=True))\n",
    "axs[0,2].set_title(\"Corrupted sagittal slice\")\n",
    "axs[0,2].axis('off')\n",
    "axs[1,0].imshow(MotionTTT_L1_mid_slice_axial)\n",
    "axs[1,0].set_title(\"MotionTTT+Th-L1 axial slice\")\n",
    "axs[1,0].axis('off')\n",
    "axs[1,1].imshow(MotionTTT_L1_mid_slice_coronal.rotate(-90, expand=True))\n",
    "axs[1,1].set_title(\"MotionTTT+Th-L1 coronal slice\")\n",
    "axs[1,1].axis('off')\n",
    "axs[1,2].imshow(MotionTTT_L1_mid_slice_sagittal.rotate(-90, expand=True))\n",
    "axs[1,2].set_title(\"MotionTTT+Th-L1 sagittal slice\")\n",
    "axs[1,2].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRIbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
